import streamlit as st
from langchain import LLMChain
from langchain.llms import OpenAI
import re
import json
import utils

st.title("ë™í™”ìƒì„± ğŸˆ")

# OpenAI API í‚¤ ì„¤ì •
openai_api_key = 'YOUR_API_KEY'
llm = OpenAI(openai_api_key=openai_api_key, model="gpt-3.5-turbo")

# ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'first_tale' not in st.session_state:
    st.session_state.first_tale = False

if 'final_tale' not in st.session_state:
    st.session_state.final_tale = False

# í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”
if 'prompt' not in st.session_state:
    st.session_state.prompt = f'''
    ë„ˆëŠ” ë‹¤ë¬¸í™” ê°€ì • ì•„ë™ë“¤ì˜ ì´ì¤‘ ì–¸ì–´ ë°œë‹¬ì„ ë•ê¸° ìœ„í•œ ë™í™”ì±… ì‘ê°€ì•¼. 

    ë‹¤ìŒ ìš”ì†Œë“¤ì„ ê¸°ì–µí•´: ë¶€ëª¨ì˜ ì„ í˜¸ ìš”ì†Œ: {st.session_state.parent_prefer}, ì•„ë™ì˜ ì„ í˜¸ ìš”ì†Œ: {st.session_state.child_prefer} 

    ê·¸ë¦¬ê³  ë‹¤ìŒ 8ê°€ì§€ ì¡°ê±´ìœ¼ë¡œ ë™í™”ë¥¼ êµ¬ì„±í•´ì¤˜ 
    1. ì•„ë™ì˜ ì„ í˜¸ ìš”ì†Œë¥¼ ë„£ì–´ì¤˜ 
    2. â€˜í‘œí˜„â€™ ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë™í™” ì•ˆì— ë„£ì–´ì¤˜ 
    3. â€˜ì¶œì‹  êµ­ê°€â€™ ë¥¼ ë™í™”ì˜ ì‚¬ê±´, ë°°ê²½, ë“±ì¥ì¸ë¬¼ ë“±ì— ì ìš©í•´ì¤˜ 
    4. â€˜ë¬¸í™”â€™ ì— ëŒ€í•œ ì„¤ëª…ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë„£ì–´ì¤˜ 
    5. ì£¼ì–´ì§„ ìš”ì†Œë“¤ì„ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆ 
    6. ë“±ì¥ì¸ë¬¼ë“¤ì€ ëª¨ë‘ ì´ë¦„ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•´ 
    7. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ì˜ì•„â€™ì´ë©´, 0~3ì„¸ ì•„ë™ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ì˜ì„±ì–´ì™€ ì˜íƒœì–´ë¥¼ ì¶”ê°€í•´ì¤˜ 
    8. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ìœ ì•„â€™ì´ë©´, 4~7ì„¸ ì•„ë™ì˜ í‘œí˜„ë ¥ì´ í–¥ìƒí•  ìˆ˜ ìˆë„ë¡ ë™í™”ë¥¼ ë§Œë“¤ì–´ì¤˜. 

    ë™í™”ì˜ ë¶„ëŸ‰ì€ ë‹¤ìŒ ì¡°ê±´ì„ ì§€ì¼œì¤˜. 
    1. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ì˜ì•„â€™ì´ë©´, 20~24í˜ì´ì§€, ê° í˜ì´ì§€ ë‹¹ ê¸€ì ìˆ˜ëŠ” 10ì ì´ìƒ 40ì ì´í•˜ë¡œ ë§Œë“¤ì–´ì¤˜. 
    2. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ìœ ì•„â€™ì´ë©´, 20~24í˜ì´ì§€, ê° í˜ì´ì§€ ë‹¹ ê¸€ì ìˆ˜ 20ì ì´ìƒ 80ì ì´í•˜ë¡œ ë§Œë“¤ì–´ì¤˜ 

    ìœ„ì˜ ì¡°ê±´ë“¤ì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì œ 1ì–¸ì–´ë¡œë§Œ ë™í™”ë¥¼ ì¨ì¤˜. 
    ë™í™”ëŠ” ì˜ˆì‹œì²˜ëŸ¼ ì¶œë ¥í•´ì¤˜ 

    ì˜ˆì‹œ: {{ì œ 1ì–¸ì–´}} ë²„ì „ 
    í˜ì´ì§€ 1: ì•„ì¹¨ì´ ë°ì•˜ì–´ìš”. ì˜¤ëŠ˜ì€ íŒŒë€ í•˜ëŠ˜ì´ í¼ì³ì§„ ë§‘ì€ ë‚ ì´ì—ìš”. ë£¨í”¼ëŠ” ì°½ë°–ì„ ë³´ë©° ê¸°ë¶„ì´ ì¢‹ì•„ì¡Œì–´ìš”. 
    í˜ì´ì§€ 2: "ì˜¤ëŠ˜ì€ ì ¤ë¦¬ì™€ ìˆ¨ë°”ê¼­ì§ˆì„ í•´ì•¼ì§€!" ë£¨í”¼ëŠ” ì¢‹ì•„í•˜ëŠ” ê³ ì–‘ì´ ì¸í˜•, ì ¤ë¦¬ë¥¼ ê¼­ ì•ˆê³  ì´ì•¼ê¸°í–ˆì–´ìš”. 
    í˜ì´ì§€ 3: ë£¨í”¼ëŠ” ì ¤ë¦¬ë¥¼ ë°ë¦¬ê³  ì§‘ ì• ê³µì›ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ê³µì›ì—ëŠ” ì‚¬ëŒë“¤ì´ ì•„ì´ìŠ¤ í•˜í‚¤ë¥¼ ì¦ê¸°ê³  ìˆì—ˆì–´ìš”. "ì™€, ì•„ì´ìŠ¤ í•˜í‚¤ì•¼!" ë£¨í”¼ëŠ” ëˆˆì´ ë°˜ì§ì˜€ì–´ìš”. 
    '''

if not st.session_state.first_tale:
    response = llm(st.session_state.prompt)
    gpt_response = response.strip()
    st.session_state.first_tale = gpt_response

    st.session_state.messages.append({"role": "assistant", "content": gpt_response})
    # ì²«ë²ˆì§¸ ë™í™” 
    with st.chat_message("assistant"):
        st.write(gpt_response)

if st.session_state.first_tale:

    if 'prompt_add' not in st.session_state:
        st.session_state.prompt_add =f'''
        1. ìƒˆë¡œìš´ ìºë¦­í„°ì™€ ì¶”ê°€í•˜ì—¬ ìƒí˜¸ì‘ìš© ìš”ì²­
        í˜„ì¬ ì´ì•¼ê¸°ëŠ” ì¼ë°˜ì ì´ê³  ì§€ë£¨í•´. ìƒˆë¡œìš´ ìºë¦­í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ìƒí˜¸ì‘ìš©í•´ì„œ ì´ì•¼ê¸°ë¥¼ ë” í¥ë¯¸ë¡­ê²Œ ë§Œë“¤ ìˆ˜ ìˆì–´. ì´ì•¼ê¸°ë¥¼ ë” í¥ë¯¸ë¡­ê²Œ ë§Œë“¤ì–´ì¤˜.
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        2. ìƒˆë¡œìš´ ì‚¬ê±´ ì¶”ê°€í•˜ì—¬ í¥ë¯¸ ì¦ì§„
        í˜„ì¬ ì´ì•¼ê¸°ëŠ” ë³´í¸ì ì´ê³  ë”°ë¶„í•´. ìƒˆë¡œìš´ ì‚¬ê±´ì„ ì¶”ê°€í•´ ì´ì•¼ê¸°ë¥¼ ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´. ì´ì•¼ê¸°ë¥¼ ë” ë§¤ë ¥ì ì´ê²Œ ë§Œë“¤ì–´ì¤˜. 
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        3. ë¶€ëª¨ê°€ ìš”ì²­í•œ í‘œí˜„ ê°•ì¡° 
        í˜„ì¬ ì´ì•¼ê¸°ì—ì„œ {st.session_state}ì— ëŒ€í•´ ë” ê°•ì¡°í•´ì¤˜. {{í‘œí˜„}}ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ì˜ ì‚¬ìš©ì„ ëŠ˜ë ¤ì„œ ë” ê°•ì¡°í•  ìˆ˜ ìˆì–´. 
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        4. ë¶€ëª¨ê°€ ìš”ì²­í•œ ë¬¸í™” ê°•ì¡°
        í˜„ì¬ ì´ì•¼ê¸°ì—ì„œ ë¶€ëª¨ì˜ ì„ í˜¸ ìš”ì†Œ ì¤‘ {{ë¬¸í™”}}ì— ëŒ€í•´ ë” ê°•ì¡°í•´ì¤˜. {{ë¬¸í™”}}ì— ëŒ€í•œ ì„¤ëª…ì„ ê°•í™”í•´ì„œ ë” ê°•ì¡°í•  ìˆ˜ ìˆì–´. 
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        5. ì´ì•¼ê¸° êµ¬ì„±ì— ëŒ€í•œ ì„¤ëª… ì‚­ì œ
        í˜„ì¬ ì´ì•¼ê¸°ì—ì„œ ì´ì•¼ê¸°ì˜ êµ¬ì„±ì— ëŒ€í•œ ì„¤ëª…ì„ ì‚­ì œí•´ì¤˜.
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        6. ì œ 2ì–¸ì–´ë¡œ ì¶œë ¥
        í˜„ì¬ ì´ì•¼ê¸°ë¥¼ ì œ 2ì–¸ì–´ë¡œ ì¶œë ¥í•´ì¤˜. 
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}

        7. í•œì–´ë³‘ìŒ ì¶œë ¥ 
        ë§Œì¼ í˜„ì¬ ì´ì•¼ê¸°ì— ì¤‘êµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì¤‘êµ­ì–´ì˜ í•œì–´ë³‘ìŒë§Œ ì¶œë ¥í•´ì¤˜. 
        í˜„ì¬ ì´ì•¼ê¸°: {st.session_state.first_tale}
        '''

    response = llm(st.session_state.prompt_add)
    gpt_response = response.strip()
    
    st.session_state.final_tale = gpt_response

    st.session_state.messages.append({"role": "assistant", "content": gpt_response})

if st.session_state.final_tale:
    # ëŒ€í™” ë‚´ìš© ì¶œë ¥
    for message in st.session_state["messages"]:
        if message.role == "assistant":
            with st.chat_message(message.role):
                # í…ìŠ¤íŠ¸ ì¶œë ¥
                st.write(message.content)
                # ìŒì„± ì¶œë ¥
                utils.generate_audio(message.content,select_language=)
        # ì´ë¯¸ì§€ ì¶œë ¥
        elif message.role == "image":
            st.image(message.content,use_column_width=True)

    # ë©”ì‹œì§€ë¥¼ json íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë²„íŠ¼
    if st.button("ì¢…ë£Œ"):
        st.session_state.check = True

    if st.session_state.check :
        filename = st.session_state.session_id+".json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump([utils.chat_message_to_dict(message) for message in st.session_state["messages"]], f, ensure_ascii=False, indent=4)
        st.success("ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤!!")