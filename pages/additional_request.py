import streamlit as st
import openai
import re,os
import json
import utils

st.title("ë™í™”ìƒì„± ğŸˆ")

# apií‚¤ ì„¤ì •
client = openai.OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'select_language' not in st.session_state:
    st.session_state.select_language = 'zh-cn'
if "check" not in st.session_state:
    st.session_state.check=False

# ì²«ë²ˆì§¸ ë™í™” ìƒì„±
if 'first_tale' not in st.session_state:
    with st.spinner("ë™í™” ë§Œë“¤ ì¬ë£Œ ìˆ˜ì§‘ í•˜ëŠ” ì¤‘..."):
        llm_1 = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹¤ë¬¸í™” ê°€ì • ì•„ë™ë“¤ì˜ ì´ì¤‘ ì–¸ì–´ ë°œë‹¬ì„ ë•ê¸° ìœ„í•œ ë™í™”ì±… ì‘ê°€ì…ë‹ˆë‹¤."},
                {"role":"user","content": f'''
                ë‹¤ìŒ ìš”ì†Œë“¤ì„ ê¸°ì–µí•´: ë¶€ëª¨ì˜ ì„ í˜¸ ìš”ì†Œ: {st.session_state.parent_prefer}, ì•„ë™ì˜ ì„ í˜¸ ìš”ì†Œ: {st.session_state.child_prefer}
            
                ê·¸ë¦¬ê³  ë‹¤ìŒ 8ê°€ì§€ ì¡°ê±´ìœ¼ë¡œ ë™í™”ë¥¼ êµ¬ì„±í•´ì¤˜ 
                1. ì•„ë™ì˜ ì„ í˜¸ ìš”ì†Œë¥¼ ë„£ì–´ì¤˜ 
                2. â€˜í‘œí˜„â€™ ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë™í™” ì•ˆì— ë„£ì–´ì¤˜ 
                3. â€˜ì¶œì‹  êµ­ê°€â€™ ë¥¼ ë™í™”ì˜ ì‚¬ê±´, ë°°ê²½, ë“±ì¥ì¸ë¬¼ ë“±ì— ì ìš©í•´ì¤˜ 
                4. â€˜ë¬¸í™”â€™ ì— ëŒ€í•œ ì„¤ëª…ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë„£ì–´ì¤˜ 
                5. ì£¼ì–´ì§„ ìš”ì†Œë“¤ì„ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆ 
                6. ë“±ì¥ì¸ë¬¼ë“¤ì€ ëª¨ë‘ ì´ë¦„ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•´ 
                7. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ì˜ì•„â€™ì´ë©´, 0~3ì„¸ ì•„ë™ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ì˜ì„±ì–´ì™€ ì˜íƒœì–´ë¥¼ ì¶”ê°€í•´ì¤˜ 
                8. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ìœ ì•„â€™ì´ë©´, 4~7ì„¸ ì•„ë™ì˜ í‘œí˜„ë ¥ì´ í–¥ìƒí•  ìˆ˜ ìˆë„ë¡ ë™í™”ë¥¼ ë§Œë“¤ì–´ì¤˜. 
            
                ë™í™”ì˜ ë¶„ëŸ‰ì€ ë‹¤ìŒ ì¡°ê±´ì„ ì§€ì¼œì¤˜. 
                1. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ì˜ì•„â€™ì´ë©´, 20~24í˜ì´ì§€, ê° í˜ì´ì§€ ë‹¹ ê¸€ì ìˆ˜ëŠ” 10ì ì´ìƒ 40ì ì´í•˜ë¡œ ë§Œë“¤ì–´ì¤˜. 
                2. ë§Œì¼ ì•„ë™ ë‚˜ì´ê°€ â€˜ìœ ì•„â€™ì´ë©´, 20~24í˜ì´ì§€, ê° í˜ì´ì§€ ë‹¹ ê¸€ì ìˆ˜ 20ì ì´ìƒ 80ì ì´í•˜ë¡œ ë§Œë“¤ì–´ì¤˜.
            
                ìœ„ì˜ ì¡°ê±´ë“¤ì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì œ 1ì–¸ì–´ë¡œë§Œ ë™í™”ë¥¼ ì¨ì¤˜. 
                ë™í™”ëŠ” ì˜ˆì‹œì²˜ëŸ¼ ì¶œë ¥í•´ì¤˜ 
            
                ì˜ˆì‹œ: í•œêµ­ì–´ ë²„ì „ 
                í˜ì´ì§€ 1: ì•„ì¹¨ì´ ë°ì•˜ì–´ìš”. ì˜¤ëŠ˜ì€ íŒŒë€ í•˜ëŠ˜ì´ í¼ì³ì§„ ë§‘ì€ ë‚ ì´ì—ìš”. ë£¨í”¼ëŠ” ì°½ë°–ì„ ë³´ë©° ê¸°ë¶„ì´ ì¢‹ì•„ì¡Œì–´ìš”. 
                í˜ì´ì§€ 2: "ì˜¤ëŠ˜ì€ ì ¤ë¦¬ì™€ ìˆ¨ë°”ê¼­ì§ˆì„ í•´ì•¼ì§€!" ë£¨í”¼ëŠ” ì¢‹ì•„í•˜ëŠ” ê³ ì–‘ì´ ì¸í˜•, ì ¤ë¦¬ë¥¼ ê¼­ ì•ˆê³  ì´ì•¼ê¸°í–ˆì–´ìš”. 
                í˜ì´ì§€ 3: ë£¨í”¼ëŠ” ì ¤ë¦¬ë¥¼ ë°ë¦¬ê³  ì§‘ ì• ê³µì›ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ê³µì›ì—ëŠ” ì‚¬ëŒë“¤ì´ ì•„ì´ìŠ¤ í•˜í‚¤ë¥¼ ì¦ê¸°ê³  ìˆì—ˆì–´ìš”. "ì™€, ì•„ì´ìŠ¤ í•˜í‚¤ì•¼!" ë£¨í”¼ëŠ” ëˆˆì´ ë°˜ì§ì˜€ì–´ìš”. 
                '''
                }
            ]
        )
        first_tale = llm_1.choices[0].message.content.strip().split('\n')
        st.session_state.first_tale=first_tale

# ìµœì¢… ë™í™” ìƒì„±
if 'final_tale' not in st.session_state:
    st.session_state.final_tale = []
    with st.spinner("ë™í™”ë¥¼ ë§Œë“¤ê³  ìˆëŠ” ì¤‘..."):
        llm_2 = client.chat.completions.create(
            model = "gpt-4",
            messages=[
                {"role": "system", "content": f"""ë‹¹ì‹ ì€ ë‹¤ë¬¸í™” ê°€ì • ì•„ë™ë“¤ì˜ ì´ì¤‘ ì–¸ì–´ ë°œë‹¬ì„ ë•ê¸° ìœ„í•œ ë™í™”ì±… ì‘ê°€ì…ë‹ˆë‹¤.
            ì œ 2ì–¸ì–´ëŠ” {st.session_state.select_language}ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ì§€ì‹œì‚¬í•­ì„ ì—„ê²©íˆ ë”°ë¼ ë™í™”ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
            1. í˜•ì‹:
               - í™€ìˆ˜ í˜ì´ì§€: í•œêµ­ì–´ ë‚´ìš©
               - ì§ìˆ˜ í˜ì´ì§€: ì§ì „ í™€ìˆ˜ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ì œ 2ì–¸ì–´ë¡œ ë²ˆì—­
               - ê° í˜ì´ì§€ëŠ” ë°˜ë“œì‹œ "í˜ì´ì§€ N: " í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤ (Nì€ í˜ì´ì§€ ë²ˆí˜¸)
               - í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1ë¶€í„° ì‹œì‘í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€
        
            2. ë‚´ìš©:
               - ë‹¤ìŒ ìš”ì†Œë“¤ì„ ë°˜ë“œì‹œ í¬í•¨: {{ì¤‘êµ­, ìœ ì•„, í•œêµ­ì–´, ì¤‘êµ­ì–´, ë‚ ì”¨ í‘œí˜„, ì¤‘êµ­ì˜ ì°¨ ë¬¸í™”}}, {{ì ¤ë¦¬, ê³ ì–‘ì´, í•˜ëŠ˜ìƒ‰, ë¸”ëŸ­ìŒ“ê¸°, í•˜ì¸„í•‘}}
               - ìƒˆë¡œìš´ ìºë¦­í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ë™í™”ë¥¼ ë” í¥ë¯¸ë¡­ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”
               - ìƒˆë¡œìš´ ì‚¬ê±´ì„ ì¶”ê°€í•˜ì—¬ ë™í™”ë¥¼ ë” ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”
               - 'ë‚ ì”¨ í‘œí˜„'ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ ì‚¬ìš©ì„ ëŠ˜ë ¤ ê°•ì¡°í•´ì£¼ì„¸ìš”
               - 'ì¤‘êµ­ì˜ ì°¨ ë¬¸í™”'ì— ëŒ€í•œ ì„¤ëª…ì„ ê°•í™”í•˜ì—¬ ê°•ì¡°í•´ì£¼ì„¸ìš”
               - ëª¨ë“  ìš”ì†Œë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œì¼œ ë™í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”
        
            3. ê¸¸ì´: ì´ 48í˜ì´ì§€ (í•œêµ­ì–´ 24í˜ì´ì§€, ì œ 2ì–¸ì–´ 24í˜ì´ì§€)
        
            4. ì£¼ì˜ì‚¬í•­:
               - ì„¤ëª… ì—†ì´ ì´ì•¼ê¸°ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”
               - ê° í˜ì´ì§€ì˜ ë‚´ìš©ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì œí•œí•´ì£¼ì„¸ìš”
        
            ì˜ˆì‹œ í˜•ì‹:
            í˜ì´ì§€ 1: [í•œêµ­ì–´ ë‚´ìš©]
            í˜ì´ì§€ 2: [ì œ 2ì–¸ì–´ë¡œ ë²ˆì—­ëœ ë‚´ìš©]
            í˜ì´ì§€ 3: [í•œêµ­ì–´ ë‚´ìš©]
            ...
        
            ì´ì „ì— ìƒì„±ëœ ë™í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„ ì§€ì‹œì‚¬í•­ì— ë§ê²Œ ìˆ˜ì •í•˜ì—¬ ìƒˆë¡œìš´ ë™í™”ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
             },
            {"role": "user", "content": f'''
            ì´ì „ì— ìƒì„±ëœ ë™í™”:
            {st.session_state.first_tale}
        
            ìœ„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ì´ ë™í™”ë¥¼ ìˆ˜ì •í•˜ê³  í™•ì¥í•˜ì—¬ ìƒˆë¡œìš´ ë²„ì „ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
            '''}
            ]
        )
        gpt_response = llm_2.choices[0].message.content.strip().split('\n')

    for page in gpt_response:
        # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
        if not page.strip():
            continue

        # ':' ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³ , ì˜¤ë¥¸ìª½ ë‚´ìš©ë§Œ ì €ì¥
        parts = page.split(':', 1)
        if len(parts) > 1:
            content = parts[1].strip()
            st.session_state.final_tale.append({"role": "assistant", "content": content})
        else:
            print(f"Warning: Unexpected format in line: {page}")

    # ì–¸ì–´ê°€ ì¤‘êµ­ì–´ì¼ ë•Œ í•œì–´ ë³‘ìŒ ì¶”ê°€
    if st.session_state.select_language == 'zh-cn':
        st.session_state['messages_2'] = []

        # ì¤‘êµ­ì–´ ë‚´ìš©ë§Œ ì¶”ì¶œ
        chinese_content = "\n".join([page["content"] for page in st.session_state.final_tale if
                                     int(page["content"].split(":")[0].split()[1]) % 2 == 0])

        # í•œì–´ë³‘ìŒ ìƒì„±
        llm_3 = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œì–´ë³‘ìŒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ì˜ í•œì–´ë³‘ìŒë§Œì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": f'''
                ë‹¤ìŒ ì¤‘êµ­ì–´ ì´ì•¼ê¸°ì˜ í•œì–´ë³‘ìŒë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ê° í˜ì´ì§€ëŠ” "í˜ì´ì§€ N:"ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤(Nì€ í˜ì´ì§€ ë²ˆí˜¸).

                ì´ì•¼ê¸°:
                {chinese_content}
                '''}
            ]
        )

        gpt_response = llm_3.choices[0].message.content.strip().split('\n')

        for page in gpt_response:
            # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if not page.strip():
                continue

            # í˜ì´ì§€ ë²ˆí˜¸ì™€ ë‚´ìš© ë¶„ë¦¬
            if page.startswith("í˜ì´ì§€"):
                parts = page.split(":", 1)
                if len(parts) > 1:
                    page_num = parts[0]
                    content = parts[1].strip()
                    st.session_state.messages_2.append({"role": "assistant", "content": f"{page_num}: {content}"})
                else:
                    print(f"Warning: Unexpected format in line: {page}")
            else:
                print(f"Warning: Line does not start with 'í˜ì´ì§€': {page}")

# ìµœì¢… ë™í™” ì¶œë ¥
if st.session_state.final_tale:
    for message in st.session_state.final_tale:
        if message["role"] == "assistant":
            with st.chat_message(message["role"]):
                # í…ìŠ¤íŠ¸ ì¶œë ¥
                st.write(message["content"])
                # # ìŒì„± ì¶œë ¥
                # # Part3: ëª¨ë¸ ì¸í¼ëŸ°ìŠ¤
                # st.markdown("ì‚¬ìš©ë  ëª¨ë¸ì€ multilingual_xtts_v2.0.2 ì…ë‹ˆë‹¤.")
                # output_name = st.text_input(
                #     "TTSë¡œ ìƒì„±ë  íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”. \
                #     ì¤‘ë³µë  ì‹œ ë®ì–´ì”Œì›Œ ì§‘ë‹ˆë‹¤. \
                #     íŒŒì¼ í™•ì¥ìëŠ” ì…ë ¥í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤.",
                #     value=""
                #     )
                # tts_input = message.content
                # prompt= re.sub("([^\x00-\x7F]|\w)(\.|\ã€‚|\?)",r"\1 \2\2", tts_input)
                # button3 = st.button("Run")
                #
                # if button3:
                #     # st.write(prompt)
                #     with st.spinner("ë³€í™˜ ì¤‘..."):
                #         # í™•ì¸
                #         st.write("ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼: " + ", ".join(os.listdir(personal_path_inputs)))
                #         gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(
                #             gpt_cond_len=30, gpt_cond_chunk_len=4, max_ref_length=60,
                #             audio_path=[
                #                 personal_path_inputs + x for x in os.listdir(personal_path_inputs)
                #             ]
                #         )
                #         out = model.inference(
                #             prompt,
                #             lang_code,
                #             gpt_cond_latent,
                #             speaker_embedding,
                #             repetition_penalty=5.0,
                #             temperature=0.75,
                #         )
                #         # HTML Display
                #         st.audio(np.expand_dims(np.array(out["wav"]), 0), sample_rate=24000)
                #         # ìë™ ì €ì¥
                #         torchaudio.save(personal_path_outputs+f"{output_name}.wav",
                #                         torch.tensor(out["wav"]).unsqueeze(0), 24000)
                #
                #         st.success('TTS ìƒì„± ë° ì €ì¥ ì™„ë£Œ')

        # ì´ë¯¸ì§€ ì¶œë ¥
        # ì—¬ê¸°ì— ì´ë¯¸ì§€ ìƒì„± ì½”ë“œ ë„£ìœ¼ë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤
        elif message["role"] == "image":
            st.image(message["content"],use_column_width=True)

    # ë©”ì‹œì§€ë¥¼ json íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë²„íŠ¼
    if st.button("ì¢…ë£Œ"):
        st.session_state.check = True

    if st.session_state.check :
        filename = st.session_state.session_id+".json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump([utils.chat_message_to_dict(message) for message in st.session_state["messages"]], f, ensure_ascii=False, indent=4)
        st.success("ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤!!")