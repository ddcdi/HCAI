import streamlit as st
import utils
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain_core.messages import ChatMessage
import json
from gtts import gTTS
import sounddevice as sd
import wave
import speech_recognition as sr

st.title("ë™í™”ë§Œë“¤ê¸° ğŸˆ")
st.markdown("ì›í•˜ëŠ” ì£¼ì œë¡œ ë™í™”ë¥¼ ì‘ì„±í•´ì£¼ëŠ” AI")

# ì–¸ì–´ ì„¤ì •
select_language = st.sidebar.selectbox(
    "ì´ì¤‘ ì–¸ì–´ ì„¤ì •",
    ("ì˜ì–´","ëŸ¬ì‹œì•„ì–´","ì¤‘êµ­ì–´","ì¼ì–´")
)

print(select_language)

# ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
utils.session_state_set()

print("ì„¸ì…˜ ID : ",st.session_state.session_id)

prompt = ""

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

topic = st.selectbox(
    "ì£¼ì œë¥¼ ê³¨ë¼ë´",
    ["ê³¼ì¼","ìºë¦­í„°","ë™ë¬¼"],
    placeholder="ì›í•˜ëŠ” ì£¼ì œ ì„ íƒí•˜ê¸°",
    index= None
)

if (topic=="ê³¼ì¼"):
    if st.button("ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§í•´ë³´ì„¸ìš”",help="ì‚¬ê³¼,ë°”ë‚˜ë‚˜,ìˆ˜ë°•..."):
        audio_file = utils.record_audio()
        text = utils.recognize_speech(audio_file)
        st.session_state.prompt = text
        print(f"í”„ë¡¬í”„íŠ¸ : {prompt}")
elif (topic=="ìºë¦­í„°"):
    prompt = st.text_input('ì›í•˜ëŠ” ìºë¦­í„°ë¥¼ ì‘ì„±í•´ë´',placeholder = 'ë½€ë¡œë¡œ,ë˜ë´‡,ë¯¸ë¯¸...')
elif (topic=="ë™ë¬¼"):
    prompt = st.text_input('ì›í•˜ëŠ” ë™ë¬¼ì„ ì‘ì„±í•´ë´',placeholder ='ê°•ì•„ì§€,ê³ ì–‘ì´,í† ë¼...')
    
if prompt:
    st.session_state.prompt = True

if st.session_state.prompt:
    if st.button("ì‹œì‘", type="primary"):
        st.session_state["started"] = True

if st.session_state["started"]:
    
    # ì´ì „ ëŒ€í™” ì €ì¥ ë° ì¶œë ¥
    utils.messages_save()

    # ì§ˆë¬¸ ë°›ê¸°
    if st.session_state.prompt and not st.session_state.select:
        user_input = st.session_state.prompt
        print(f"user_input : {user_input}")
        user_message = ChatMessage(role="user", content=user_input)
        st.session_state["messages"].append(user_message)
        
        with st.chat_message("user"):
            st.write(user_input)

        # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        with st.spinner("ì—´ì‹¬íˆ ë™í™”ë¥¼ ë§Œë“¤ê³  ìˆëŠ”ì¤‘..."):
            if "tokenizer" not in st.session_state or "model" not in st.session_state:
                try:
                    st.session_state["tokenizer"], st.session_state["model"] = utils.load_model()
                except Exception as e:
                    st.error(f"ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.stop()
        
        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    response = utils.generate_text(
                        user_input, st.session_state["tokenizer"], st.session_state["model"]
                    )
                    st.markdown(response)
                except Exception as e:
                    st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.stop()
        
        assistant_message = ChatMessage(role="assistant", content=response)
        st.session_state["messages"].append(assistant_message)
        st.session_state.select = True
    
    # ì´ë¯¸ ì£¼ì œë¥¼ ì„ íƒí–ˆì„ë•Œ
    elif st.session_state.prompt:
        user_input = st.chat_input("ì›í•˜ì‹ ê±¸ ë§ì”€í•´ë³´ì„¸ìš”")

        user_message = ChatMessage(role="user", content=user_input)
        st.session_state["messages"].append(user_message)
        
        with st.chat_message("user"):
            st.write(user_input)

        # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        with st.spinner("ì—´ì‹¬íˆ ë™í™”ë¥¼ ë§Œë“¤ê³  ìˆëŠ”ì¤‘..."):
            if "tokenizer" not in st.session_state or "model" not in st.session_state:
                try:
                    st.session_state["tokenizer"], st.session_state["model"] = utils.load_model()
                except Exception as e:
                    st.error(f"ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.stop()
        
        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    response = utils.generate_text(
                        user_input, st.session_state["tokenizer"], st.session_state["model"]
                    )
                    st.markdown(response)
                    
                    # ë‹µë³€ ìŒì„± íŒŒì¼ë¡œ ì¬ìƒ
                    utils.generate_audio(response,select_language)
                except Exception as e:
                    st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.stop()
                
        
        assistant_message = ChatMessage(role="assistant", content=response)
        st.session_state["messages"].append(assistant_message)

    # ë©”ì‹œì§€ë¥¼ json íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë²„íŠ¼
    if st.button("ì¢…ë£Œ"):
        st.session_state.check = True

    if st.session_state.check :
        filename = st.session_state.session_id+".json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump([utils.chat_message_to_dict(message) for message in st.session_state["messages"]], f, ensure_ascii=False, indent=4)
        st.success("ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤!!")

else:
    st.markdown("ì‘ì„±ì„ ì™„ë£Œí•˜ê³  ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
